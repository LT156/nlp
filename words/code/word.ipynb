{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/github_code/nlp/words/resource/stanford-english-corenlp-2016-01-10/stanford-english-corenlp-2016-01-10-models.jar\n",
      "F:/github_code/nlp/words/resource/stanford-english-corenlp-2016-01-10/stanford-parser-3.6.0-models.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\software\\Tools\\Anaconda3\\envs\\artemis_env_1\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The StanfordParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "Could not find stanford-parser\\.jar jar file at F:/github_code/nlp/words/resource/stanford-english-corenlp-2016-01-10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a347b3de57b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_path_to_models_jar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_path_to_jar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStanfordParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_models_jar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_path_to_models_jar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstanford_parser_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the man looks sad and miserable like he heard some terrible news that shattered his very soul\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software\\Tools\\Anaconda3\\envs\\artemis_env_1\\lib\\site-packages\\nltk\\parse\\stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software\\Tools\\Anaconda3\\envs\\artemis_env_1\\lib\\site-packages\\nltk\\parse\\stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_jar, path_to_models_jar, model_path, encoding, verbose, java_options, corenlp_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mis_regex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             ),\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         )\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software\\Tools\\Anaconda3\\envs\\artemis_env_1\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m             raise LookupError(\n\u001b[1;32m--> 735\u001b[1;33m                 \u001b[1;34mf\"Could not find {name_pattern} jar file at {path_to_jar}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m             )\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: Could not find stanford-parser\\.jar jar file at F:/github_code/nlp/words/resource/stanford-english-corenlp-2016-01-10"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "from get_demo_path import get_path\n",
    "demo_path = get_path()+'/words'\n",
    "stanford_parser_dir = demo_path+'/resource/stanford-english-corenlp-2016-01-10'\n",
    "my_path_to_models_jar = stanford_parser_dir + \"/stanford-english-corenlp-2016-01-10-models.jar\"\n",
    "my_path_to_jar = stanford_parser_dir + \"/stanford-parser-3.6.0-models.jar\"\n",
    "print(my_path_to_models_jar)\n",
    "print(my_path_to_jar)\n",
    "parser = StanfordParser(path_to_models_jar=my_path_to_models_jar, path_to_jar=stanford_parser_dir)\n",
    "(result, )=parser.parse(\"the man looks sad and miserable like he heard some terrible news that shattered his very soul\".split())\n",
    "print(str(result).replace('/n',''))\n",
    "result.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "def traverse_tree(tree):\n",
    "    # print(\"tree:\", tree)\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            traverse_tree(subtree)\n",
    "        else:\n",
    "            print(str(subtree))\n",
    "traverse_tree(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Tree\n",
    "\n",
    "#parse_str =\"(ROOT (S (NP (PRP You)) (VP (MD could) (VP (VB say) (SBAR (IN that) (S (NP (PRP they)) (ADVP (RB regularly)) (VP (VB catch) (NP (NP (DT a) (NN shower)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ adds) (PP (TO to) (NP (NP (PRP$ their) (NN exhilaration)) (CC and) (NP (FW joie) (FW de) (FW vivre))))))))))))) (. .)))\"\n",
    "#parse_str =\"(ROOT (S (SBAR (IN Though) (S (NP (PRP he)) (VP (VBD was) (ADJP (RB very) (JJ rich))))) (, ,) (NP (PRP he)) (VP (VBD was) (ADVP (RB still)) (ADJP (RB very) (JJ unhappy))) (. .)))\"\n",
    "parse_str = str(result).replace('/n','')\n",
    "t =Tree.fromstring(parse_str)\n",
    "#print t\n",
    "\n",
    "subtexts = []\n",
    "for subtree in t.subtrees():\n",
    "    if subtree.label()==\"S\" or subtree.label()==\"SBAR\":\n",
    "        #print subtree.leaves()\n",
    "        subtexts.append(' '.join(subtree.leaves()))\n",
    "#print subtexts\n",
    "\n",
    "presubtexts = subtexts[:]       # ADDED IN EDIT for leftover check\n",
    "\n",
    "for i in reversed(range(len(subtexts)-1)):\n",
    "    subtexts[i] = subtexts[i][0:subtexts[i].index(subtexts[i+1])]\n",
    "\n",
    "for text in subtexts:\n",
    "    print(text)\n",
    "\n",
    "# ADDED IN EDIT - Not sure for generalized cases\n",
    "leftover = presubtexts[0][presubtexts[0].index(presubtexts[1])+len(presubtexts[1]):]\n",
    "print(leftover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loaded = np.load(demo_path+'/source/new_output/words_feature.npz',allow_pickle=True)\n",
    "pd.DataFrame(loaded['feature_df'],columns=loaded['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(loaded['feature_df'],columns=loaded['columns'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('artemis_env_1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03591697f24511c6f09dd0796522b0630e3a776f3674a03662de1335a317f0eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
